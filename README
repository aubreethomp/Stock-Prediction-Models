# CM332 Data Mining Final Project
## Aubree Thompson and Anna Phelps
The purpose of the original project was to create a model to predict stock prices. Another goal of the original paper was to determine which models would work the best in different sectors. The original paper discussed the creation of six models to predict stock price. The paper focused on three sectors: IT, Banking, and Health. Their data was collected from Yahoo finance. The original paper concluded that the best time series and economic model was ARIMA, the best machine learning model was MARS, and the best deep learning model was LSTM. They determined which model was the best by looking at the Root Mean Square Error, RMSE for short, divided by the mean of close values. We aim to recreate the original models and validate the results concerning the effectiveness of the models. The training data is from 2004 to 2018. We plan to extend the model to account for the impact of COVID. We will do this by including data from 2019 to 2023. We will use data web scraped from NASDAQ, containing historical stock market values from the top 10 most popular stocks (most likely will not use all of these stocks); this data set contains values from 2013 to 2023. We expect that the models trained on the original 2004 to 2018 data will not accurately predict the stock values due to the unexpected changes in the stock market brought on by COVID. Causing potenially different results from the original paper. Original research: https://arxiv.org/pdf/2111.01137

We preprocessed our data in order to visualize it properly in the previous step. We needed to clean to date columns and change them to a date/time object. This was essential as the close value for each date was what we were examining. This is also what was done in the original research paper. We also had to clean the close column specifically since there were symbols in monetary columns. This was essentially just cleaning so we could carry out the steps in the paper. Previously visualized where to seperate the test and training data but we just used the last year of our data for the test data like the paper did.

The original study trained several models. The first was the Holt Winters Exponential Smoothing model. In the study, they used a 94:6 split of training to test data. This split was done so that the data from 2004 to 2018 was used to train the model, and then the 2019 data was used to test the model. The original study focused on building models for Banking, IT, and Health sectors. We will validate their conclusions regarding the IT sector by building models from CSCO and META. We will expand on their results by building models from a different sector (Starbucks). The study mentioned that they set seasonal to "add" and seasonal periods to 5, so that is what we used. The original study used rmse to determine the quality of the model.

We used RMSE to test our models.

Our test rmses are significantly higher than those from the original study. Most of theirs were under 1, while some of ours were over 100. There are several possible explanations. One is that the data from COVID made it harder for the model to make predictions. Another explanation is that our data was different than the original data, so their might have been better suited for the models chosen. A third possible explanation is that our code is different. Their code was not included in their paper, so we had to use the written explanation of how they built the models, so they might have done more to perfect the models that they didn't include in their written explanation.

In general, the LSTM model seemed to preform the best out of all the models. The visualizations included in the model building section illustrate this.